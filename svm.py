# -*- coding: utf-8 -*-
"""SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p2qHoFK8F02S7KLCv7ZBKLs0e4CDVEeo
"""

# Importing the libraries

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.metrics import accuracy_score

from google.colab import files
uploaded = files.upload()

from __future__ import print_function
# Import the dataset
dataset = pd.read_csv('hw2_question3.csv', header=None)
full_dataset = dataset.iloc[:, :].values

total_samples = len(dataset)

print('Total number of samples is {}'.format(total_samples))
print('Input shape is {}'.format(dataset.shape))

dataset.head(5)

# https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf
columns_to_hot_encode = [1, 6, 7, 13, 14, 15, 25, 28]

for col in columns_to_hot_encode:
    dataset[str(col)+'_neg'] = np.where(dataset[col] == -1, 1, 0)
    dataset[str(col)+'_zero'] = np.where(dataset[col] == 0, 1, 0)
    dataset[str(col)+'_pos'] = np.where(dataset[col] == 1, 1, 0)

dataset.head(5)

dataset = dataset.drop(columns=[1, 6, 7, 13, 14, 15, 25, 28])

dataset.head(5)

# move the target at the end
df1 = dataset.pop(30)
dataset[30] = df1
dataset.head(5)

# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html
# shuffle the samples 
dataset = dataset.sample(frac=1, random_state=9728).reset_index(drop=True)
dataset.head(5)

# divide the sammples

total_train_samples = (int)((2/3)*total_samples)
total_test_samples = total_samples - total_train_samples

print('Total number of training samples is {}'.format(total_train_samples))
print('Total number of test samples is {}'.format(total_test_samples))

training_set = dataset.head(total_train_samples)
test_set = dataset.tail(total_test_samples)

training_set.head(5)

training_set.shape

test_set.shape

# SVM starts here
training_set_data = training_set.iloc[:, :].values
X = training_set_data[:, :-1]
y = training_set_data[:, 46]

test_set_data = test_set.iloc[:, :].values
X_test = test_set_data[:, :-1]
y_test = test_set_data[:, 46]

X.shape

y.shape

X_test.shape

y_test.shape

# https://pythonhow.com/measure-execution-time-python-code/
import time
# import the SVM library
from sklearn import svm

svm_classifier = svm.SVC(kernel='linear', C=1.0, gamma='scale')

start = time.time()
svm_classifier.fit(X, y)
end = time.time()

print('Time for training : ', end - start)

# Predicting the Test set results
y_pred = svm_classifier.predict(X_test)

print(accuracy_score(y_test, y_pred))

# K-fold validation
# code referenced from this book - https://www.manning.com/
#                           books/deep-learning-with-python
k = 3
train_data = X
train_targets = y
num_val_samples = train_data.shape[0] // k
accuracy = []
times = []

# 10^{-5},10^{-4},...,0.1, 1, 3,5,10,
C_values = [1e-5, 3e-5, 9e-5, 1e-4, 3e-4, 9e-4, 1e-3, 3e-3, 9e-3, 0.01, 0.03, 0.09, 0.1, 0.3, 0.9]
C_values = C_values + list(range(1, 51, 1)) + [5*n for n in range(11,20+1)]
training_set_copy = training_set.copy()

for c in C_values:
    all_scores = []
    all_times = []
    for i in range(k):
        val_data =\
        train_data[i * num_val_samples: (i + 1) * num_val_samples]
        val_targets =\
        train_targets[i * num_val_samples: (i + 1) * num_val_samples]

        partial_train_data = np.concatenate(
            [train_data[:i * num_val_samples],
             train_data[(i + 1) * num_val_samples:]],
            axis=0)
        partial_train_targets = np.concatenate(
            [train_targets[:i * num_val_samples],
             train_targets[(i + 1) * num_val_samples:]],
            axis=0)
        """
        print(val_data.shape)
        print(val_targets.shape)
        print(partial_train_data.shape)
        print(partial_train_targets.shape)
        """
        val_classifier = svm.SVC(kernel='linear', C=c, gamma='scale')
        
        start = time.time()
        val_classifier.fit(partial_train_data, partial_train_targets)
        end = time.time()
        
        val_pred = val_classifier.predict(val_data)
        
        acc = accuracy_score(val_targets, val_pred)
        """
        print('Time is ', end-start)
        print('Accuracy is  ', acc)
        print('-------------------------')
        """
        all_scores.append(acc)
        all_times.append(end-start)
    accuracy.append(np.mean(all_scores))
    times.append(np.mean(all_times))
    print('C is {} | Accuracy is {} | Time is {} '.format(c, np.mean(all_scores), np.mean(all_times)))

import operator
index, value = max(enumerate(accuracy), key=operator.itemgetter(1))
print(value)
print(C_values[index])
print('Best C is {} | Accuracy is {} | Time is {} '.format(C_values[index], value, times[index]))

svm_classifier = svm.SVC(kernel='linear', C=C_values[index], gamma='scale')

start = time.time()
svm_classifier.fit(X, y)
end = time.time()

print('Time for training : ', end - start)

# Predicting the Test set results
y_pred = svm_classifier.predict(X_test)

print(accuracy_score(y_test, y_pred))

plt.plot(C_values, accuracy, 'b', label='Accuracy obtained during 3 fold cross-validation')
plt.title('C value VS Accuracy')
plt.xlabel('C Values')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

plt.plot(C_values, times, 'b', label='Average time taken')
plt.title(' C value VS Average training time')
plt.xlabel('C value')
plt.ylabel('Average training time')
plt.legend()
plt.show()

# K-fold validation
# code referenced from this book - https://www.manning.com/
#                           books/deep-learning-with-python
k = 3
train_data = X
train_targets = y
num_val_samples = train_data.shape[0] // k
accuracy = []
times = []

l1 = list(range(1, 101, 1))
# 10^{-5},10^{-4},...,0.1, 1, 3,5,10,
C_values = [1e-5, 3e-5, 9e-5, 1e-4, 3e-4, 9e-4, 1e-3, 3e-3, 9e-3, 0.01, 0.03, 0.09, 0.1, 0.3, 0.9, 1, 3] + [5*n for n in range(1,20+1)]
training_set_copy = training_set.copy()

DEGREE = [2, 3, 4, 5, 6, 7, 8, 9, 10]
best_c_value = []
best_accuray_value = []

for degree in DEGREE:
    accuracy = []
    times = []
    for c in C_values:
        all_scores = []
        all_times = []
        for i in range(k):
            val_data =\
            train_data[i * num_val_samples: (i + 1) * num_val_samples]
            val_targets =\
            train_targets[i * num_val_samples: (i + 1) * num_val_samples]

            partial_train_data = np.concatenate(
                [train_data[:i * num_val_samples],
                 train_data[(i + 1) * num_val_samples:]],
                axis=0)
            partial_train_targets = np.concatenate(
                [train_targets[:i * num_val_samples],
                 train_targets[(i + 1) * num_val_samples:]],
                axis=0)
            """
            print(val_data.shape)
            print(val_targets.shape)
            print(partial_train_data.shape)
            print(partial_train_targets.shape)
            """
            val_classifier = svm.SVC(kernel='poly', degree=degree, C=c, gamma='scale')

            start = time.time()
            val_classifier.fit(partial_train_data, partial_train_targets)
            end = time.time()

            val_pred = val_classifier.predict(val_data)

            acc = accuracy_score(val_targets, val_pred)
            """
            print('Time is ', end-start)
            print('Accuracy is  ', acc)
            print('-------------------------')
            """
            all_scores.append(acc)
            all_times.append(end-start)
        accuracy.append(np.mean(all_scores))
        times.append(np.mean(all_times))
        print('Degree is {} | C is {} | Accuracy is {} | Time is {} '.format(degree, c, np.mean(all_scores), np.mean(all_times)))
    index, value = max(enumerate(accuracy), key=operator.itemgetter(1))    
    print('Degree is {} | Best C is {} | Best Accuracy is {} | Time is {} '.format(degree, C_values[index] , value, times[index]))
    best_c_value.append(C_values[index])
    best_accuray_value.append(value)

print(best_c_value)
print(best_accuray_value)

index, value = max(enumerate(best_accuray_value), key=operator.itemgetter(1))
print('Best degree is {} | Best C is {} | Accuracy is {} '.format(DEGREE[index], best_c_value[index], value))

svm_classifier = svm.SVC(kernel='poly', degree=DEGREE[index], C=best_c_value[index], gamma='scale')

start = time.time()
svm_classifier.fit(X, y)
end = time.time()

print('Time for training : ', end - start)

# Predicting the Test set results
y_pred = svm_classifier.predict(X_test)

print(accuracy_score(y_test, y_pred))

# K-fold validation
# code referenced from this book - https://www.manning.com/
#                           books/deep-learning-with-python
k = 3
train_data = X
train_targets = y
num_val_samples = train_data.shape[0] // k
accuracy = []
times = []

# 10^{-5},10^{-4},...,0.1, 1, 3,5,10,
C_values = [1e-5, 3e-5, 9e-5, 1e-4, 3e-4, 9e-4, 1e-3, 3e-3, 9e-3, 0.01, 0.03, 0.09, 0.1, 0.3, 0.9]
C_values = C_values + list(range(1, 51, 1)) + [5*n for n in range(11,20+1)]
training_set_copy = training_set.copy()

for c in C_values:
    all_scores = []
    all_times = []
    for i in range(k):
        val_data =\
        train_data[i * num_val_samples: (i + 1) * num_val_samples]
        val_targets =\
        train_targets[i * num_val_samples: (i + 1) * num_val_samples]

        partial_train_data = np.concatenate(
            [train_data[:i * num_val_samples],
             train_data[(i + 1) * num_val_samples:]],
            axis=0)
        partial_train_targets = np.concatenate(
            [train_targets[:i * num_val_samples],
             train_targets[(i + 1) * num_val_samples:]],
            axis=0)
        """
        print(val_data.shape)
        print(val_targets.shape)
        print(partial_train_data.shape)
        print(partial_train_targets.shape)
        """
        val_classifier = svm.SVC(kernel='rbf', C=c, gamma='scale')
        
        start = time.time()
        val_classifier.fit(partial_train_data, partial_train_targets)
        end = time.time()
        
        val_pred = val_classifier.predict(val_data)
        
        acc = accuracy_score(val_targets, val_pred)
        """
        print('Time is ', end-start)
        print('Accuracy is  ', acc)
        print('-------------------------')
        """
        all_scores.append(acc)
        all_times.append(end-start)
    accuracy.append(np.mean(all_scores))
    times.append(np.mean(all_times))
    print('C is {} | Accuracy is {} | Time is {} '.format(c, np.mean(all_scores), np.mean(all_times)))

import operator
index, value = max(enumerate(accuracy), key=operator.itemgetter(1))
print(value)
print(C_values[index])
print('Best C is {} | Accuracy is {} | Time is {} '.format(C_values[index], value, times[index]))

svm_classifier = svm.SVC(kernel='rbf', C=C_values[index], gamma='scale')

start = time.time()
svm_classifier.fit(X, y)
end = time.time()

print('Time for training : ', end - start)

# Predicting the Test set results
y_pred = svm_classifier.predict(X_test)

print(accuracy_score(y_test, y_pred))

